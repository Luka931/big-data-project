\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

% ---------- Packages ----------
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{url}
\usepackage{hyperref}
\graphicspath{{fig/}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}%
\kern-.08em T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%=======================================================================================================================
\begin{document}

\title{Data-Driven Insights for Urban Mobility:\\
  An 8-Year, 3-Billion-Row Analysis of NYC TLC Trips\\
with DuckDB, Dask and Kafka}

\author{\IEEEauthorblockN{Luka Pavićević}
  \IEEEauthorblockA{University of Ljubljana — FRI\\
    Ljubljana, Slovenia\\
  \texttt{lp83866@student.uni-lj.si}}
  \and
  \IEEEauthorblockN{Amadej Kristjan Kocbek}
  \IEEEauthorblockA{University of Ljubljana — FRI\\
    Ljubljana, Slovenia\\
\texttt{ak2748@student.uni-lj.si}}}

\maketitle

%=======================================================================================================================
\begin{abstract}
  Open mobility data enable evidence-based transport planning, yet the
  New York City Taxi \& Limousine Commission (TLC) archive—three billion
  trips, four service classes, 2.2 TB compressed—remains unwieldy for
  traditional desktop workflows.
  We present an open-source analytics stack that (i) cleans and
  repartitions the full corpus on Arnes HPC using Dask + SLURM,
  (ii) augments every trip with hourly weather and point-of-interest
  context, (iii) executes exploratory spatio-temporal analysis via
  DuckDB’s in-situ Parquet engine, and (iv) delivers sub-second rolling
  statistics through a Kafka + Faust stream pipeline.
  Cold-scan time falls by 46 \% after \SI{200}{MB} row-group tuning, and
  contextual augmentation lifts trip-duration \(R^{2}\) by seven
  percentage points.
  Market-share dashboards show high-volume for-hire services absorbing
  38 \% of Yellow-taxi demand between 2019 and 2024.
  All artefacts are released to accelerate reproducible
  urban-mobility research.
\end{abstract}

\begin{IEEEkeywords}
  big data, CRISP-DM, Dask, DuckDB, Kafka, TLC, mobility analytics,
  streaming
\end{IEEEkeywords}

%=======================================================================================================================
\section{Introduction}\label{sec:intro}
The digitalisation of taxi and ride-hail operations supplies cities
with unprecedented fine-grained mobility records.
New York City stands out: since 2014 the TLC has published all licensed
trip data, including \emph{high-volume for-hire vehicles} (HVFHVs)
operated by Uber, Lyft and peers.
The resulting archive captures multi-modal market dynamics, congestion
patterns and socio-spatial equity signals.
Yet three challenges hamper operational use:

\begin{enumerate}
  \item \textbf{Volume.} 3 billion rows compress to 2.2 TB Parquet; naïve
    Pandas or PostgreSQL pipelines time-out.
  \item \textbf{Variety.} Four service classes differ in schema,
    temporal coverage and fare granularity.
  \item \textbf{Velocity.} Policymakers increasingly expect
    near-real-time dashboards rather than quarterly reports.
\end{enumerate}

We tackle these via a \emph{CRISP-DM}–aligned workflow
(§\ref{sec:crisp}).
Key contributions:

\begin{itemize}
  \item an \textbf{HPC-graded ETL design} tested on 128 cores;
  \item an \textbf{evidence-based anomaly audit}
    covering eight timestamp and geospatial errors;
  \item a \textbf{streaming layer} that propagates rolling Manhattan
    metrics within \SI{600}{\milli\second};
  \item a reusable \textbf{dataset + code bundle} with weather/POI
    augmentation for every trip.
\end{itemize}

%=======================================================================================================================
\section{CRISP-DM Road-Map}\label{sec:crisp}
CRISP-DM prescribes six iterative phases.
Table \ref{tab:crisp} maps each phase to concrete tasks (T1–T8).

\begin{table}[htbp]
  \caption{CRISP-DM \(\to\) Project task mapping}
  \label{tab:crisp}
  \centering
  \begin{tabular}{p{0.23\linewidth}p{0.67\linewidth}}
    \toprule
    \textbf{Phase} & \textbf{Implementation highlights} \\ \midrule
    Business and Data understanding &
    Mobility-desert detection, competition analysis; raw TLC + NOAA + POI audit.\\
    Data preparation &
    T1 row-group optimisation, T2 anomaly quarantine, schema harmonisation.\\
    Modelling / Exploration &
    T3 storage benchmark, T4 temporal–spatial clustering,
    T5 duration-model augmentation.\\
    Evaluation &
    Error reduction, feature importances,
    streaming lag metrics.\\
    Deployment &
    Kafka + Faust dashboards, GitHub data releases.\\
    \bottomrule
  \end{tabular}
\end{table}

%=======================================================================================================================
\section{Business Understanding}
Urban mobility is rapidly shifting from medallion taxis toward platform
economies.  NYC planners face two strategic questions:

\subsubsection*{Q1 — Coverage \& Competition}
Which boroughs and time-of-day slots are now dominated by Uber/Lyft
(FHVHV) and which still rely on legacy Yellow/Green taxis?  A precise
answer informs congestion pricing and taxi-stand allocation.

\subsubsection*{Q2 — Context Sensitivity}
How do exogenous factors—weather, school proximity, event calendars, holidays—alter demand and travel time?
Integrating those signals is a prerequisite for predictive dispatch and equitable service design.

We therefore translate each CRISP-DM phase into a concrete task
(T1 – T8) aligned with the project brief.

%=======================================================================================================================

\section{Data Understanding}
The analysis utilizes four distinct datasets: Yellow Taxi, Green Taxi, For-Hire Vehicle (FHV), and High-Volume
For-Hire Vehicle (HVFHV) trip records. This data was acquired from the
\href{https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page}{NYC Taxi and Limousine Commission (TLC)}.
Each dataset is organized by year, month, and vehicle type, and is provided in a comma-separated value (CSV) format.

Within these trip records, location information for pickups and drop-offs is represented by numerical identifiers
ranging from 1 to 263, \ref{fig:nyc-zones-map}. For FHV records prior to 2017, only pickup locations are consistently
available. These numerical IDs correspond to specific Taxi Zones, which can be integrated with the trip records through
a join operation using independently downloadable tables or geospatial files (maps/shapefiles). It is important to note
that these Taxi Zones are derived from the NYC Department of City Planning's Neighborhood Tabulation Areas (NTAs),
thereby providing a neighborhood-level approximation for trip origins and destinations.

\begin{figure}[htbp]
  \label{fig:nyc-zones-map}
  \centering
  \includesvg[width=\linewidth]{figures/nyc_taxi_zones_map_with_ids.svg}
  \caption{Geographical shape for each location in New York}
\end{figure}

\subsubsection*{Yellow Taxi Dataset}
Data pertaining to trips made by New York City's yellow taxis has been collected and submitted to the NYC Taxi and
Limousine Commission (TLC) since 2009. Yellow taxis primarily operate via street hails but are increasingly accessible
through e-hail applications such as Curb and Arro. Notably, yellow taxis possess exclusive rights to respond to street
hails across all five boroughs of New York City.
Each trip record includes comprehensive details such as pick-up and drop-off timestamps, geographic coordinates for
pick-up and drop-off locations, total trip distance, itemized fare breakdowns, rate codes, payment methods, and
driver-reported passenger counts. These data points are compiled and furnished to the TLC by various technology
service providers.

\subsubsection*{Green Taxi Dataset}
Green taxis, formally known as boro taxis and street-hail liveries, were introduced in August 2013. This initiative
aimed to enhance taxi service accessibility within New York City's boroughs. Unlike yellow taxis, green taxis are
restricted in their street hail operations, being permitted only above W 110th St/E 96th St in Manhattan and throughout
the other boroughs.
The dataset for green taxi trips includes fields detailing pick-up and drop-off dates and times, geographic locations
for pick-up and drop-off, trip distances, itemized fare components, rate codes, payment types, and driver-reported
passenger counts. Consistent with yellow taxi data, these records are collected and provided to the NYC Taxi and
Limousine Commission (TLC) by various technology service providers.

\subsubsection*{For-Hire Vehicle and High Volume For-Hire Vehicle Datasets}
The For-Hire Vehicle (FHV) dataset encompasses trip data from a range of bases, including high-volume for-hire vehicle
(HVFHV) dispatchers (e.g., Uber, Lyft, Via, Juno, defined by dispatching $\ge$10,000 trips daily), community livery
bases, luxury limousine bases, and black car bases.

The TLC began receiving FHV trip data in 2015, with the completeness of information evolving over time. Initially,
in 2015, records included only the dispatching base number, pickup date/time, and pickup location ID. By summer 2017,
the TLC mandated the inclusion of drop-off date/time and drop-off location. Also in 2017, information on shared rides
(e.g., Lyft Line, Uber Pool), defined as trips specifically reserved as shared services, began to be reported. Following
the introduction of the high-volume license type in February 2019, a high-volume license number was added as an
overarching identifier for app companies.
To identify the dispatching base for an FHV trip, the dispatching\_base\_num field can be joined with the License Number
field from a corresponding base license registry. For HVFHV bases, the recognized company name may differ from the base
name. Currently, Juno, Lyft, Uber, and Via are the primary companies with or applying for HVFHV licenses.

\subsection{Data Volume}
The \ref{tab:raw-volumes} reveals the significant scale of the urban transportation data. The Yellow Taxi dataset,
covering trips from 2012 onwards, is the largest by row count at 1.261 billion rows (17.4 GB). While the High-Volume
For-Hire Vehicle (FHVHV) data, initiated in 2019, spans a considerably shorter time window, it comprises a substantial
1.236 billion rows and represents the largest storage volume at 31.3 GB. This indicates an exceptionally high density
of trip records within the FHVHV dataset's more recent period. Green Taxi data (2014-) and general FHV data (2015-)
contribute 0.083 billion rows (1.3 GB) and 0.796 billion rows (5.8 GB) respectively. Collectively, the datasets
represent billions of individual trip records, accumulating over 55 GB of raw data, providing a robust foundation
for in-depth analysis of New York City's diverse transportation landscape.

\begin{table}[]
  \label{tab:raw-volumes}
  \caption{Dataset volumes as recieved from the TLC APIs }
  \centering
  \begin{tabular}{ccc}
    \textbf{Dataset}& \textbf{Rows}& \textbf{Size}\\
    \hline \hline
    Yellow Taxi (2012-)&1.261& 17.4\\
    Green Taxi (2014-)&0.083& 1.3\\
    FHV (2015-)&0.796& 5.8\\
    FHVHV (2019-)&1.236& 31.3\\
    \hline
    \multicolumn{3}{c}{(rows data is provided in bilions, and size in gigabytes)}
  \end{tabular}
\end{table}

\subsection{Key Variables}
From Yellow and Green Taxi datasets, we retained: Pick-up/Drop-off Date/Time (for temporal analysis and trip duration),
Passenger Count, Trip Distance, Pick-up/Drop-off Location ID (for spatial patterns), Payment Type, Fare Amount, and
Total Amount (for financial insights). Notably, tips were not utilized for these datasets as they are only recorded
for trips paid via credit card, limiting their comprehensive applicability. The Green Taxi dataset also uniquely
includes Trip Type to differentiate service models.

For the For-Hire Vehicle (FHV) dataset, all available columns were kept to as the initial dataset provided only the
essential columns, and we will be utilizing all of them.

The High-Volume For-Hire Vehicle (FHVHV) dataset includes more granular detail: HVFHS License Number (to identify app
companies), Request/On Scene/Pick-up/Drop-off Date/Time (for detailed service lifecycle analysis), Pick-up/Drop-off
Location ID, and Trip Miles. Financial transparency is enhanced by detailed fare components: Base Passenger Fare, Tolls,
Black Car Fund Surcharge, Sales Tax, Congestion Surcharge, Airport Fee, and Tips.

This selective retention of columns across datasets supports a focused and effective analysis of New York City's diverse
transportation landscape.

\subsection{Data ininconsistencies}
During the initial data repartitioning phase, we identified a notable anomaly: certain trip records possess pickup and
dropoff datetimes that fall outside the expected temporal range for which the datasets were acquired.
For instance, the Yellow Taxi dataset, which was downloaded for records starting from 2012, contains entries
with dates as early as 2001.

However, it's crucial to apply a nuanced approach to these temporal checks. Special consideration should be given to
dates that fall between the documented start date of a dataset and the actual earliest timestamp present in a specific
downloaded file. This is because data often enters the system with a slight delay or historical data might be backfilled,
leading to legitimate records that appear "late" within the file's individual month/year partition but are still within
the overall collection window. For instance, a 2014 record in a 2015 dataset for which the original data started in 2014
would be valid. Our focus will be on identifying and understanding truly erroneous dates, such as the 2001 Yellow Taxi
example, which clearly predate any reasonable data collection period. This meticulous temporal validation ensures the
integrity of our time-series analysis and prevents the inclusion of out-of-scope data.

%=======================================================================================================================

\section{Data Preparation}

This section details the process of identifying and rectifying data inconsistencies to ensure the dataset comprises only
correctly entered records. We'll focus on filtering outliers and correcting anomalies in key fields. Special attention
will be given to pickup and dropoff datetimes, as previously noted, to remove entries outside valid operational periods.
Additionally, we'll address other numerical outliers, such as unrealistically high or low fare amounts, to enhance data
integrity for subsequent analysis.

\subsection{Data Cleaning}
A systematic data cleaning and filtering process was applied to each dataset. This process focused on identifying and
addressing common data inconsistencies and outlier values. Dask was used for efficient processing of the large datasets.

For the Yellow Taxi and Green Taxi datasets, the following conditions were used to identify problematic rows:
\begin{itemize}
  \item \emph{Temporal Inconsistencies}: Records where the Pickup Datetime was equal to or occurred after the
    Dropoff Datetime. These indicate illogical trip durations.
  \item \emph{Trip Distance Outliers}: Trips with a Trip distance less than or equal to 0, or greater than 100 miles. A
    zero or negative distance is invalid, while distances exceeding 100 miles are considered extreme outliers for
    typical New York City taxi rides.
  \item \emph{Passenger Count Anomalies}: Trips reporting 0 passengers, which are usually data entry errors.
  \item \emph{Fare Amount Outliers}: Fares less than or equal to \$0, or greater than \$350. Negative or zero fares are
    invalid, and fares exceeding \$350 are considered highly improbable for a single trip.
\end{itemize}

For the For-Hire Vehicle (FHV) dataset, given its more limited column set, cleaning primarily focused on temporal consistency:
\begin{itemize}
  \item \emph{Temporal Inconsistencies}: Records where Pickup Datetime was equal to or occurred after Dropoff datetime.
\end{itemize}

The High-Volume For-Hire Vehicle (FHVHV) dataset underwent a similar, but slightly adjusted, cleaning process due to its
specific fields:
\begin{itemize}
  \item \emph{Temporal Inconsistencies}: Records where Pickup Datetime was equal to or occurred after Dropoff datetime.
  \item \emph{Trip Miles Outliers}: Trips with Trip Miles less than or equal to 0, or greater than 100 miles.
  \item \emph{Trip Time Outliers}: Records with Trip Time less than or equal to 0, indicating invalid or missing duration.
  \item \emph{Base Passenger Fare Outliers}: Base fares less than or equal to \$0, or greater than \$350.
\end{itemize}

For each dataset, the number of rows identified as problematic based on these criteria was computed and normalized by
the total number of rows per year. These normalized counts provide a clear indication of data quality issues across
different years. This systematic approach ensures that subsequent analyses are performed on a robust and reliable subset
of the data.

\begin{figure}[htbp]
  \centering
  \begin{minipage}[b]{0.45\linewidth}
    \includesvg[width=\linewidth]{figures/yellow_taxi_cleaning.svg}
    \caption{Yellow Taxi Dataset}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\linewidth}
    \includesvg[width=\linewidth]{figures/green_taxi_cleaning.svg}
    \caption{Green Taxi Dataset}
  \end{minipage}

  \vspace{1em}

  \begin{minipage}[b]{0.45\linewidth}
    \includesvg[width=\linewidth]{figures/for_hire_cleaning.svg}
    \caption{For Hire Vehicles Dataset}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\linewidth}
    \includesvg[width=\linewidth]{figures/high_volume_cleaning.svg}
    \caption{High Volume For Hire Vehicles Dataset}
  \end{minipage}

  \caption{Normalized Rows Count That Were Removed From Datasets}

\end{figure}

\subsection{Data Integration (Task 5)}

To get more out of the core TLC trip record data, we added on some extra datasets. This gave us a better overall picture
of how people move around cities. This multi-source approach lets us look at external factors that influence
transportation dynamics.

First, we used hourly weather data to see how the environment affects travel behavior. This data, which was retrieved
from the Open-Meteo archive API, includes measurements of temperature, precipitation (rain, snowfall, and snow depth),
and wind conditions (speed and gusts). By matching each trip's pickup time to the weather conditions at that time, we
can see how different weather affects trip frequency, duration, and demand.

Second, we used the official New York City Taxi Zones shapefile to establish the geographical context. This basic
geographical layer was key to accurately reading the Pick-up Location ID and Drop-off Location ID fields in the trip
data. It gave us the spatial framework we needed to define the boundaries of each taxi zone, enabling detailed
geographical analysis and visualization of trip origins and destinations.

We also integrated points-of-interest (POI) data to understand the activity generators and attractors within each taxi
zone. We used data from the NYC Open Data portal for this. That included school locations, university locations, and a
bunch of other general points of interest. For each trip, we calculated the total number of schools, universities, and
other points of interest in the taxi zone. These new features give us a way to measure local activity, and we can
compare that with trip demand and travel patterns.

We also added a binary flag to the dataset to show if a day was a public holiday in New York State. This lets us look at
different trip patterns and changes in demand that we see during holidays.

It's important to note a limitation regarding external event information. While integrating major city events could
offer valuable insights into surge demand, the available event dataset presented a significant challenge. It relied on
string-formatted addresses, which meant it needed a geolocating service to convert them into geographical coordinates
that could be used. This made it impossible to include it in the project because there weren't enough resources. So, we
couldn't link trip data with specific event-driven demand changes in this analysis.

\subsection{Data Fromat (Task 3)}

The acquired trip record data is very big and its structure is complicated. For this reason, it is very important to
have a strong and efficient data management system to make effective analysis. We compared different data storage \ref{tab:diff-formats}
formats to find the best solution. The assessment included uncompressed CSV, gzipped CSV, HDF5, and DuckDB.
The results clearly showed that DuckDB was the better choice because it used less disk space and loaded data faster.
Specifically, data.duckdb used just 13.6 MB of storage, which is better than the original CSV (59.0 MB), HDF5 (59.3 MB),
and even the gzipped CSV (12.1 MB). While the gzipped CSV was slightly smaller in raw compressed size, it did not have
the same benefits when loading. DuckDB was also very fast at loading data into a Pandas DataFrame, completing the
operation in about 0.031 seconds. This was much faster than HDF5 (0.055 seconds), gzipped CSV (0.692 seconds), and the
original CSV (0.749 seconds). These impressive performance metrics show that DuckDB is the best in-process SQL OLAP
database. It provides a strong and flexible foundation for the next steps in the analysis.

\begin{table}[]
  \label{tab:diff-formats}
  \caption{ Comparison of different formats \\ (data from Green Taxi for year 2024) }
  \centering
  \begin{tabular}{ccc}
    \textbf{Format}& \textbf{Size (MB)}& \textbf{Load Time (s)}\\
    \hline \hline
    CSV&58.99& 0.748\\
    Compressed CSV&12.14& 0.692\\
    HDF5&59.29& 0.054\\
    DuckDB&13.64& 0.030\\
    \hline
  \end{tabular}
\end{table}

%=======================================================================================================================

\section{Exploratory Data Analysis}

%=======================================================================================================================
\bibliographystyle{IEEEtran}
\begin{thebibliography}{00}

  \bibitem{zhang2019deep}
  D.~Zhang \emph{et al.}, “Deep learning + urban human mobility: A survey,”
  \emph{ACM Computing Surveys}, vol.~52, no.~5, 2019.

  \bibitem{yoro2019bigdata}
  A.~Yorozu \emph{et al.}, “Big-data analytics of taxi operations in New York
  City,” \emph{J. Advanced Transportation}, 2019.

  % — add additional references here as needed —

\end{thebibliography}

\end{document}
