{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1a15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb6d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask Dashboard link: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:53:01,473 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:35771 (pid=272169) exceeded 95% memory budget. Restarting...\n",
      "2025-05-20 16:53:01,922 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:35771' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-fused-toparquetdata-5a8c4ae664710635ee744adf3daa2d0c', 8)} (stimulus_id='handle-worker-cleanup-1747752781.921746')\n",
      "2025-05-20 16:53:01,937 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=2, threads_per_worker=1, memory_limit='16GB')\n",
    "client = Client(cluster)\n",
    "print(f\"Dask Dashboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'tpep_pickup_datetime',\n",
    "\t'tpep_dropoff_datetime',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "    'payment_type',\n",
    "    'fare_amount',\n",
    "    'total_amount'\n",
    "]\n",
    "\n",
    "yellow_taxi = dd.read_parquet(\"data/trip_record_data/yellow_taxi/*.parquet\", columns = columns)\n",
    "yellow_taxi['year'] = dd.to_datetime(yellow_taxi['tpep_pickup_datetime']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a58f8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:23:12,861 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 10.60 GiB -- Worker memory limit: 14.90 GiB\n",
      "2025-05-20 16:23:34,114 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 11.95 GiB -- Worker memory limit: 14.90 GiB\n",
      "2025-05-20 16:23:34,160 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 11.50 GiB -- Worker memory limit: 14.90 GiB\n",
      "2025-05-20 16:23:56,264 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 10.49 GiB -- Worker memory limit: 14.90 GiB\n",
      "2025-05-20 16:27:22,237 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 12.09 GiB -- Worker memory limit: 14.90 GiB\n",
      "2025-05-20 16:27:22,261 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 11.54 GiB -- Worker memory limit: 14.90 GiB\n"
     ]
    }
   ],
   "source": [
    "yellow_taxi.to_parquet(\n",
    "        \"data/trip_record_partitioned/yellow-taxi\",\n",
    "        engine='pyarrow',\n",
    "        partition_on=['year'],\n",
    "        write_index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9064c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'lpep_pickup_datetime',\n",
    "\t'lpep_dropoff_datetime',\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'payment_type',\n",
    "    'fare_amount',\n",
    "    'total_amount',\n",
    "    'trip_type'\n",
    "]\n",
    "\n",
    "green_taxi = dd.read_parquet(\"data/trip_record_data/green_taxi/*.parquet\", columns = columns)\n",
    "green_taxi['year'] = dd.to_datetime(green_taxi['lpep_pickup_datetime']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_taxi.to_parquet(\n",
    "        \"data/trip_record_partitioned/green-taxi\",\n",
    "        engine='pyarrow',\n",
    "        partition_on=['year'],\n",
    "        write_index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d37185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_hire = dd.read_parquet(\"data/trip_record_data/for_hire/*.parquet\")\n",
    "for_hire['year'] = dd.to_datetime(for_hire['pickup_datetime']).dt.year\n",
    "for_hire['SR_Flag'] = for_hire['SR_Flag'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb77f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_hire.to_parquet(\n",
    "        \"data/trip_record_partitioned/for_hire\",\n",
    "        engine='pyarrow',\n",
    "        partition_on=['year'],\n",
    "        write_index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask Dashboard link: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 11:34:04,503 - tornado.application - ERROR - Uncaught exception GET /status/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='127.0.0.1:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lukap/.local/lib/python3.13/site-packages/tornado/websocket.py\", line 938, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "  File \"/home/lukap/.local/lib/python3.13/site-packages/tornado/web.py\", line 3301, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/home/lukap/.local/lib/python3.13/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=1, threads_per_worker=1, memory_limit='25GB')\n",
    "client = Client(cluster)\n",
    "print(f\"Dask Dashboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a08bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'hvfhs_license_num',\n",
    "    'request_datetime',\n",
    "    'on_scene_datetime',\n",
    "    'pickup_datetime',\n",
    "    'dropoff_datetime',\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "    'trip_miles',\n",
    "    'tolls',\n",
    "    'bcf',\n",
    "    'sales_tax',\n",
    "    'congestion_surcharge',\n",
    "    'airport_fee',\n",
    "    'tips'    \n",
    "]\n",
    "\n",
    "high_volume = dd.read_parquet(\"data/trip_record_data/high_volume/*.parquet\", columns = columns, blocksize=\"64MB\")\n",
    "high_volume['year'] = dd.to_datetime(high_volume['pickup_datetime']).dt.year\n",
    "high_volume['PULocationID'] = high_volume['PULocationID'].astype(\"int32\")\n",
    "high_volume['DOLocationID'] = high_volume['DOLocationID'].astype(\"int32\")\n",
    "high_volume['airport_fee'] = high_volume['airport_fee'].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b2159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 19:53:07,422 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 16.39 GiB -- Worker memory limit: 23.28 GiB\n",
      "2025-05-21 19:58:55,407 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 16.32 GiB -- Worker memory limit: 23.28 GiB\n",
      "2025-05-21 20:03:55,505 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 16.84 GiB -- Worker memory limit: 23.28 GiB\n",
      "2025-05-21 20:04:44,514 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 18.67 GiB -- Worker memory limit: 23.28 GiB\n",
      "2025-05-21 20:04:54,443 - distributed.worker.memory - WARNING - Worker is at 1% memory usage. Resuming worker. Process memory: 391.49 MiB -- Worker memory limit: 23.28 GiB\n"
     ]
    }
   ],
   "source": [
    "high_volume.to_parquet(\n",
    "        \"data/trip_record_partitioned/high_volume\",\n",
    "        engine='pyarrow',\n",
    "        partition_on=['year'],\n",
    "        write_index = False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
