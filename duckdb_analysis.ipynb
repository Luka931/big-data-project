{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "parquet_path = \"data/merged_output_parquet/*.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512c31e",
   "metadata": {},
   "source": [
    "First we test that we can read our parquet files with DuckDB by checking that all columns are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5445da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.read_parquet(f\"{parquet_path}\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77c60c",
   "metadata": {},
   "source": [
    "We do some initial data anlysis by calculating the Average, Minimum, and Maximum values for the most interesting columns.\n",
    "\n",
    "Also we calculate the speed of execution se we can later compare it to Dask SQL.\n",
    "\n",
    "We see that we should do some filtering because minimum for trip_distance and total_amount is negative, which are not results that should be possible. Also we should cap the total_amount because we doubt that anyone would pay 1000003.8 for a taxi ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc60b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "duckdb.sql(f\"\"\" select \n",
    "                avg(passenger_count) avg_passengers, \n",
    "                avg(trip_distance),\n",
    "                min(trip_distance),\n",
    "                max(trip_distance),\n",
    "                avg(total_amount),\n",
    "                min(total_amount),\n",
    "                max(total_amount) \n",
    "           from '{parquet_path}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1cfa14",
   "metadata": {},
   "source": [
    "Calculate the median trip distance of rides that were done for each day of the year, we separete the results by month so we can visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ae73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result = duckdb.sql(f\"\"\" select month(tpep_pickup_datetime), day(tpep_pickup_datetime), round(mean(trip_distance), 2) as avg_distance from  \n",
    "           '{parquet_path}'\n",
    "           group by day(tpep_pickup_datetime), month(tpep_pickup_datetime) \n",
    "           order by month(tpep_pickup_datetime), day(tpep_pickup_datetime)\n",
    "\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf04734",
   "metadata": {},
   "source": [
    "We are going to visualize the results we have calculated earlier, so we get a better understanding for the trips taken during the year. As we can see, for the first four months of the year, people are usually taking shorter trips compared to the other parts of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d83e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['month', 'day', 'avg_distance'])\n",
    "df = df.sort_values(by=['month', 'day'])\n",
    "df['date'] = df.apply(lambda row: str(int(row['day'])) + \"-\" + str(int(row['month'])), axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "plt.bar(df['date'], df['avg_distance'], label='Daily Avg Distance')\n",
    "\n",
    "plt.title('Average Trip Distance Over the Year', fontsize=18)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Trip Distance (miles)', fontsize=14) \n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.xaxis.set_major_locator(ticker.MaxNLocator(12))\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator(df[df['day'] == 1].index))\n",
    "# ax.axis.set_major_locator( df[df['day'] == 1]['date']) \n",
    "\n",
    "# Adding a grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout() # Adjusts plot to ensure everything fits without overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30172b3",
   "metadata": {},
   "source": [
    "Next we take a look at the median fare amount during different hours of the day. As we can see the taxi drivers earn the most in the early morning, during 4, 5, 6, hours in the morning. Also there are some inconsistencies which should be looked at, we have a negative median fare amount for the 8th hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d765a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result =  duckdb.sql(f\"\"\" select hour(tpep_pickup_datetime), round(mean(fare_amount), 2) as avg_amount from  \n",
    "           '{parquet_path}'\n",
    "           group by hour(tpep_pickup_datetime)\n",
    "           order by hour(tpep_pickup_datetime)\n",
    "\"\"\").fetchall()\n",
    "\n",
    "df = pd.DataFrame(result, columns=['hour', 'fare_amount'])\n",
    "df = df.sort_values(by=['hour'])\n",
    "\n",
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "plt.bar(df['hour'], df['fare_amount'], label='Hourly Average Fare Amount')\n",
    "\n",
    "plt.title('Hourly Average Fare Amount', fontsize=18)\n",
    "plt.xlabel('Hour', fontsize=14)\n",
    "plt.ylabel('Average Fare Amount', fontsize=14) \n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.xaxis.set_major_locator(ticker.MaxNLocator(12))\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator(df['hour'].index))\n",
    "# ax.axis.set_major_locator( df[df['day'] == 1]['date']) \n",
    "\n",
    "# Adding a grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout() # Adjusts plot to ensure everything fits without overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34656997",
   "metadata": {},
   "source": [
    "We take a look at the borughs that people usually take trips between. And also calculate the time needed to calculate this query in order to compare it to the Dask SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "duckdb.sql(f\"\"\" select borough_pickup, borough_dropoff, count(*) as trips_count from  \n",
    "           '{parquet_path}'\n",
    "           where borough_pickup is not null and borough_dropoff is not null\n",
    "           group by borough_pickup, borough_dropoff\n",
    "           order by trips_count desc\n",
    "\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb840e",
   "metadata": {},
   "source": [
    "In the following cells, we try to make some conclusion based on the data we have added to the original data. We take the look at the fact if the day is rainy or if it is a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\" select is_holiday, round(avg(trip_distance), 2), round(mean(tip_amount), 2) median_tip from  \n",
    "           '{parquet_path}'\n",
    "           group by is_holiday \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbab726",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\" select round(avg(no_trips)) avg_trips_holiday from\n",
    "           (\n",
    "                select year(tpep_pickup_datetime), month(tpep_pickup_datetime), day(tpep_pickup_datetime), count(*) as no_trips from  \n",
    "                '{parquet_path}'\n",
    "                where is_holiday is true\n",
    "                group by year(tpep_pickup_datetime), month(tpep_pickup_datetime), day(tpep_pickup_datetime)\n",
    "           )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ddcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\" select round(avg(no_trips)) as avg_trips_non_holiday from\n",
    "           (\n",
    "                select year(tpep_pickup_datetime), month(tpep_pickup_datetime), day(tpep_pickup_datetime), round(count(*)) as no_trips from  \n",
    "                '{parquet_path}'\n",
    "                where is_holiday is false\n",
    "                group by year(tpep_pickup_datetime), month(tpep_pickup_datetime), day(tpep_pickup_datetime)\n",
    "           )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bca887",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\" select round(avg(trip_distance), 2), round(mean(tip_amount), 2) median_tip from  \n",
    "           '{parquet_path}'\n",
    "           where \"rain (mm)\" >= 0.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\" select round(avg(trip_distance), 2), round(mean(tip_amount), 2) median_tip from  \n",
    "           '{parquet_path}'\n",
    "           where \"rain (mm)\" < 0.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd418310",
   "metadata": {},
   "source": [
    "We are creating an Dask client in order to compute the queries using the Dask SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, \n",
    "from dask_sql import Context\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=1, memory_limit='8GB')\n",
    "print(f\"Dask Dashboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"data/merged_output_parquet\" \n",
    "c = Context()\n",
    "\n",
    "\n",
    "dask_table_name = \"taxi_data\"\n",
    "c.create_table(dask_table_name, parquet_path, format=\"parquet\")\n",
    "\n",
    "\n",
    "sql_query = f\"\"\" select borough_pickup, borough_dropoff, count(*) as trips_count from  \n",
    "           '{dask_table_name}'\n",
    "           where borough_pickup is not null and borough_dropoff is not null\n",
    "           group by borough_pickup, borough_dropoff\n",
    "           order by trips_count desc\n",
    "\"\"\"\n",
    "\n",
    "sql_query_initial = f\"\"\"\n",
    "    select \n",
    "                avg(passenger_count) avg_passengers, \n",
    "                avg(trip_distance),\n",
    "                min(trip_distance),\n",
    "                max(trip_distance),\n",
    "                avg(total_amount),\n",
    "                min(total_amount),\n",
    "                max(total_amount) \n",
    "           from '{dask_table_name}'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04106bde",
   "metadata": {},
   "source": [
    "For this initial query we can see that by using DuckDB we can save a lot of time compared to Dask SQL implementation. \n",
    "For my local implementation I can notice that using DuckDB needs 2.11 ms to compute this query, where as Dask SQL requires 6.48 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "c.sql(sql_query_initial).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d20b324",
   "metadata": {},
   "source": [
    "The same thing can be noticed in this example here, DuckDB requires significently less time to calculate the same query comapred to Dask SQL. \n",
    "We can see that the Dask SQL locally takes 46.4 s to compute this query, while DuckDB need only 669 ms, which is more than 50 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c.sql(sql_query).compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
