{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d0a1eb",
   "metadata": {},
   "source": [
    "# Docker \n",
    "\n",
    "In order to set up Kafka and Zookeeper, we are going to utilize docker containers. We just need to run the \"docker-compose up -d\" command, and it is going to create the required containers for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer,  Consumer, KafkaException, KafkaError\n",
    "import json\n",
    "import duckdb\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38621a02",
   "metadata": {},
   "source": [
    "# Producer\n",
    "\n",
    "Here we defin the producer which is going to publish messages to the 'yellow-taxi' topic. \n",
    "This topic is to be automatically created in our Kafka instance which is running on the local machine, on the port 9092.\n",
    "When we send this message we are only going to make a console log about it delivery, if it fails we notify the user, otherwise print out the topic we are writting to, the partition and the message offset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP_SERVERS = 'localhost:9092'\n",
    "YELLOW_TAXI_TOPIC = 'yellow-taxi'\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to topic '{msg.topic()}' \"\n",
    "              f\"[{msg.partition()}] @ offset {msg.offset()}\")\n",
    "\n",
    "def create_producer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': BOOTSTRAP_SERVERS,\n",
    "        'client.id': 'python-producer'\n",
    "    }\n",
    "    try:\n",
    "        producer = Producer(conf)\n",
    "        print(\"Confluent Kafka Producer initialized successfully.\")\n",
    "        return producer\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Confluent Kafka Producer: {e}\")\n",
    "        return None\n",
    "\n",
    "def send_message(producer, topic_name, message_value):\n",
    "    if producer is None:\n",
    "        print(\"Producer is not initialized. Cannot send message.\")\n",
    "        return\n",
    "    try:\n",
    "        producer.produce(topic_name,\n",
    "                         value=json.dumps(message_value).encode('utf-8'),\n",
    "                         callback=delivery_report)\n",
    "        \n",
    "        producer.poll(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending message: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ea3a0",
   "metadata": {},
   "source": [
    "## Generator functions\n",
    "\n",
    "We are going to utillize the ducdb library to fetch the data from the parquet files. We decided to do it this way (even though it is not the most optimal), because our files are not sorted by pickup data, and we are low on storage to write it once again to the drive.\n",
    "We fetch the data in batches of 1.000.000 rows, and return it in the Pandas dataframe so it can be later used by the producer.\n",
    "We provided functions both for the High Volume Dataset, and Yellow taxi dataset, because we are going to utilize both for the final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_high_volume(batch_size = 1_000_00):\n",
    "    high_volume_path = 'data/trip_record_partitioned/high_volume/year=2021/*.parquet'\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        df = duckdb.sql(f\"\"\"\n",
    "            select \n",
    "                pickup_datetime, \n",
    "                dropoff_datetime, \n",
    "                PULocationID, \n",
    "                DOLocationID, \n",
    "                trip_miles as distance, \n",
    "                base_passenger_fare as base_fare, \n",
    "                congestion_surcharge as congestion_charge, \n",
    "                tips\n",
    "            from '{high_volume_path}'\n",
    "            order by pickup_datetime\n",
    "            limit {batch_size}\n",
    "            offset {offset}\n",
    "        \"\"\").df()\n",
    "        df['pickup_datetime'] = df['pickup_datetime'].astype('str')\n",
    "        df['dropoff_datetime'] = df['dropoff_datetime'].astype('str')\n",
    "\n",
    "        offset = offset + batch_size\n",
    "\n",
    "        yield df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2263c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_yellow_taxi(batch_size = 10_000_000):\n",
    "    yellow_taxi_path = 'data/trip_record_partitioned/yellow-taxi/year=2021/*.parquet'\n",
    "    offset = 0\n",
    "    \n",
    "    while True:\n",
    "        df = duckdb.sql(f'''\n",
    "            select \n",
    "                tpep_pickup_datetime as pickup_datetime,\n",
    "                tpep_dropoff_datetime as dropoff_datetime,\n",
    "                PULocationID,\n",
    "                DOLocationID,\n",
    "                trip_distance as distance,\n",
    "                fare_amount as base_fare,\n",
    "                passenger_count,\n",
    "                payment_type\n",
    "            from '{yellow_taxi_path}'\n",
    "            order by pickup_datetime\n",
    "            limit {batch_size}\n",
    "            offset {offset}\n",
    "        ''').df()\n",
    "        df['pickup_datetime'] = df['pickup_datetime'].astype('str')\n",
    "        df['dropoff_datetime'] = df['dropoff_datetime'].astype('str')\n",
    "\n",
    "\n",
    "        offset = offset + batch_size\n",
    "        yield df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574edb09",
   "metadata": {},
   "source": [
    "### Running the producer\n",
    "\n",
    "We need to initialize our producer, and generator function in order to publish data to the topic. \n",
    "After we initialize them, we take our rows of data batch by batch and publish them to the topic. We do this until we run out of the rows in the dataset. \n",
    "After each abtch we flush the producer so our queue does not get filled up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_batch_yellow_taxi()\n",
    "\n",
    "producer = create_producer()\n",
    "\n",
    "if producer:\n",
    "    for records in gen:\n",
    "        if len(records) == 0:\n",
    "            break\n",
    "\n",
    "        for rec in records:\n",
    "            send_message(producer, YELLOW_TAXI_TOPIC, rec)\n",
    "\n",
    "        producer.flush()\n",
    "    print(\"All messages sent and flushed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf8628",
   "metadata": {},
   "source": [
    "# Consumer\n",
    "\n",
    "We need to define the conumer which is going to subscribe to the same topic as our producer. So as before, it is going to subscribe to the 'yellow-taxi' topic, on the local machine using the port 9092. It is going to start processing from the earliest available message.\n",
    "For the each recieved message we are going to log it to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_ID = 'my_confluent_consumer_group'\n",
    "BOOTSTRAP_SERVERS = 'localhost:9092'\n",
    "YELLOW_TAXI_TOPIC = 'yellow-taxi'\n",
    "\n",
    "def create_consumer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': BOOTSTRAP_SERVERS,\n",
    "        'group.id': GROUP_ID,\n",
    "        'auto.offset.reset': 'earliest',\n",
    "        'enable.auto.commit': True,     \n",
    "        'auto.commit.interval.ms': 1000 \n",
    "    }\n",
    "    try:\n",
    "        consumer = Consumer(conf)\n",
    "        print(\"Confluent Kafka Consumer initialized successfully.\")\n",
    "        return consumer\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Confluent Kafka Consumer: {e}\")\n",
    "        return None\n",
    "\n",
    "def consume_messages(consumer):\n",
    "    consumer.subscribe([YELLOW_TAXI_TOPIC])\n",
    "    print(f\"Topic: {YELLOW_TAXI_TOPIC}, Group: {GROUP_ID}\")\n",
    "\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            decoded_value = json.loads(msg.value().decode('utf-8'))\n",
    "            print(decoded_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70862b1",
   "metadata": {},
   "source": [
    "Here we define our consumer and use it to recieve the messages from the topic. In order to stop it we can terminate the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = create_consumer()\n",
    "if consumer:\n",
    "    consume_messages(consumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8feda",
   "metadata": {},
   "source": [
    "### Running in paralle\n",
    "\n",
    "We can run consumer and producer in paralle if we run the 'producer.py' and 'consumer.py' from different terminal session. This way we can see the true power of Kafka messaging system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
