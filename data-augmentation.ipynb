{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79c3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import holidays\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f180daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones = gpd.read_file(\"data/taxi-zones/taxi_zones.shp\")\n",
    "schools = gpd.read_file(\"data/school-locations/SchoolPoints_APS_2024_08_28.shp\").to_crs(taxi_zones.crs)\n",
    "\n",
    "# aggregating the data about the number of schools for each taxi zone\n",
    "schools_per_zone = gpd.sjoin(schools, taxi_zones, how=\"inner\", predicate=\"within\").groupby(\"LocationID\").size().reset_index(name='number_of_schools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8401614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(geom_str):\n",
    "    try:\n",
    "        coords_str = geom_str.split('(')[1].split(')')[0].split()\n",
    "        lon = float(coords_str[0])\n",
    "        lat = float(coords_str[1])\n",
    "        return Point(lon, lat)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbc95f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the data about the number of points of interest for each taxi zone\n",
    "poi_df = pd.read_csv(\"data/points-of-interest.csv\")\n",
    "poi_df[\"geometry\"] =  poi_df['the_geom'].apply(extract_coords)\n",
    "poi_gdf = gpd.GeoDataFrame(poi_df, geometry='geometry', crs=\"EPSG:4326\").to_crs(taxi_zones.crs)\n",
    "pois_per_zone = gpd.sjoin(poi_gdf, taxi_zones, how=\"inner\", predicate=\"within\").groupby(\"LocationID\").size().reset_index(name='number_of_pois')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e15155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the data about the number of universities for each taxi zone\n",
    "university_df = pd.read_csv(\"data/universities.csv\")\n",
    "university_df[\"geometry\"] =  university_df['the_geom'].apply(extract_coords)\n",
    "university_gdf = gpd.GeoDataFrame(university_df, geometry='geometry', crs=\"EPSG:4326\").to_crs(taxi_zones.crs)\n",
    "universities_per_zone = gpd.sjoin(university_gdf, taxi_zones, how=\"inner\", predicate=\"within\").groupby(\"LocationID\").size().reset_index(name='number_of_universities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1c501f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>number_of_schools</th>\n",
       "      <th>number_of_pois</th>\n",
       "      <th>number_of_universities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Queens</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID                     zone        borough  number_of_schools  \\\n",
       "0           1           Newark Airport            EWR                  0   \n",
       "1           2              Jamaica Bay         Queens                  0   \n",
       "2           3  Allerton/Pelham Gardens          Bronx                  6   \n",
       "3           4            Alphabet City      Manhattan                  7   \n",
       "4           5            Arden Heights  Staten Island                  2   \n",
       "\n",
       "   number_of_pois  number_of_universities  \n",
       "0               0                       0  \n",
       "1              30                       0  \n",
       "2              46                       0  \n",
       "3             133                       0  \n",
       "4               8                       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = taxi_zones[['LocationID', 'zone', 'borough']].copy()\n",
    "\n",
    "merged_df = pd.merge(merged_df, schools_per_zone, on='LocationID', how='left')\n",
    "merged_df = pd.merge(merged_df, pois_per_zone, on='LocationID', how='left')\n",
    "merged_df = pd.merge(merged_df, universities_per_zone, on='LocationID', how='left')\n",
    "\n",
    "merged_df['number_of_schools'] = merged_df['number_of_schools'].fillna(0).astype(int)\n",
    "merged_df['number_of_pois'] = merged_df['number_of_pois'].fillna(0).astype(int)\n",
    "merged_df['number_of_universities'] = merged_df['number_of_universities'].fillna(0).astype(int)\n",
    "\n",
    "zones_final = merged_df[['LocationID', 'zone', 'borough', 'number_of_schools', 'number_of_pois', 'number_of_universities']]\n",
    "\n",
    "zones_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_final.to_csv(\"zones_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd861c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask Dashboard link: http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "client = Client(n_workers=4, threads_per_worker=1, memory_limit='8GB')\n",
    "print(f\"Dask Dashboard link: {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a538f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = dd.read_parquet(\"data/taxi-data/*.parquet\")\n",
    "zones_data = dd.read_csv(\"zones_final.csv\")\n",
    "weather_data = dd.read_csv(\"data/weather-data.csv\", skiprows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2348432",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_holidays = holidays.US() \n",
    "\n",
    "def check_holiday(date):\n",
    "    if pd.isna(date):\n",
    "        return False \n",
    "    return date in us_holidays\n",
    "\n",
    "def is_holiday(date_series):\n",
    "    return date_series.apply(check_holiday, meta=('tpep_pickup_datetime_rounded', 'bool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2328cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukap/.local/lib/python3.13/site-packages/dask/dataframe/multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+------------------------------------------+----------------+----------------+\n",
      "| Merge columns                            | left dtype     | right dtype    |\n",
      "+------------------------------------------+----------------+----------------+\n",
      "| ('tpep_pickup_datetime_rounded', 'time') | datetime64[us] | datetime64[ns] |\n",
      "+------------------------------------------+----------------+----------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "taxi_data['tpep_pickup_datetime_rounded'] = taxi_data['tpep_pickup_datetime'].dt.round('h')\n",
    "weather_data['time'] = dd.to_datetime(weather_data['time']).dt.round('h')\n",
    "taxi_data['is_holiday'] = taxi_data['tpep_pickup_datetime_rounded'].apply(\n",
    "    check_holiday,\n",
    "    meta=pd.Series([], dtype='bool', name='is_holiday')\n",
    ")\n",
    "\n",
    "merged_df = dd.merge(taxi_data, zones_data, left_on='PULocationID', right_on='LocationID', how='left')\n",
    "merged_df = dd.merge(merged_df, zones_data, left_on='DOLocationID', right_on='LocationID', how='left', suffixes=('_pickup', '_dropoff'))\n",
    "merged_df = dd.merge(merged_df, weather_data, left_on='tpep_pickup_datetime_rounded', right_on='time', how='left')\n",
    "merged_df = merged_df.drop(columns=['LocationID_pickup', 'LocationID_dropoff', 'time', 'Unnamed: 0_pickup', 'Unnamed: 0_dropoff', 'tpep_pickup_datetime_rounded'])\n",
    "\n",
    "merged_df[\"airport_fee\"] = merged_df[\"airport_fee\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc63763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:33:53,053 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.72 GiB -- Worker memory limit: 7.45 GiB\n",
      "2025-05-09 22:33:53,244 - distributed.worker.memory - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 6.31 GiB -- Worker memory limit: 7.45 GiB\n",
      "2025-05-09 22:33:53,338 - distributed.worker.memory - WARNING - Worker is at 73% memory usage. Resuming worker. Process memory: 5.44 GiB -- Worker memory limit: 7.45 GiB\n",
      "2025-05-09 22:33:54,851 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.38 GiB -- Worker memory limit: 7.45 GiB\n",
      "2025-05-09 22:33:55,153 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.19 GiB -- Worker memory limit: 7.45 GiB\n",
      "2025-05-09 22:33:55,276 - distributed.worker.memory - WARNING - Worker is at 33% memory usage. Resuming worker. Process memory: 2.50 GiB -- Worker memory limit: 7.45 GiB\n"
     ]
    }
   ],
   "source": [
    "merged_df.to_parquet(\"data/merged_output_parquet/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
